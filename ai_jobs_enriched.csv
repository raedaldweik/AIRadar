source,title,company,team_or_department,commitment,location,remote,salary,skills,posted_at,updated_at,apply_url,description
Greenhouse,"[Expression of Interest] Research Scientist/Engineer, Alignment Finetuning",anthropic,AI Research & Engineering,,"San Francisco, CA",, 2025,python,,2025-09-10,https://job-boards.greenhouse.io/anthropic/jobs/4520279008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role: As a Research Scientist/Engineer on the Alignment Finetuning team at Anthropic, you'll lead the development and implementation of techniques aimed at training language models that are more aligned with human values: that demonstrate better moral reasoning, improved honesty, and good character. You'll work to develop novel finetuning techniques and to use these to demonstrably improve model behavior. Note: For this role, we conduct all interviews in Python. We have filled our headcount for 2025. However, we are leaving this form open as an expression of interest since we expect to be growing the team in the future, and we will review your application when we do. As such, you may not hear back on your application to this team until the new year Responsibilities: Develop and implement novel finetuning techniques using synthetic data generation and advanced training pipelines Use these to train models to have better alignment properties including honesty, character, and harmlessness Create and maintain evaluation frameworks to measure alignment properties in models Collaborate across teams to integrate alignment improvements into production models Develop processes to help automate and scale the work of the team You may be a good fit if you: Have an MS/PhD in Computer Science, ML, or related field, or equivalent experience Possess strong programming skills, especially in Python Have experience with ML model training and experimentation Have a track record of implementing ML research Demonstrate strong analytical skills for interpreting experimental results Have experience with ML metrics and evaluation frameworks Excel at turning research ideas into working code Can identify and resolve practical implementation challenges Strong candidates may also have: Experience with language model finetuning Background in AI alignment research Published work in ML or alignment Experience with synthetic data generation Familiarity with techniques like RLHF, constitutional AI, and reward modeling Track record of designing and implementing novel training approaches Experience with model behavior evaluation and improvement The expected salary range for this position is: Annual Salary: $315,000 — $340,000 USD Logistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience. Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate"
Greenhouse,"[Expression of Interest] Research Scientist/Engineer, Honesty",anthropic,AI Research & Engineering,,"New York City, NY; San Francisco, CA",, 2025,"llm, python, rag",,2025-09-10,https://job-boards.greenhouse.io/anthropic/jobs/4532887008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role: As a Research Scientist/Engineer focused on honesty within the Finetuning Alignment team, you'll spearhead the development of techniques to minimize hallucinations and enhance truthfulness in language models. Your work will focus on creating robust systems that are accurate and reflect their true levels of confidence across all domains, and that work to avoid being deceptive or misleading. Your work will be critical for ensuring our models maintain high standards of accuracy and honesty across diverse domains. Note: The team is based in New York and so we have a preference for candidates who can be based in New York. For this role, we conduct all interviews in Python. We have filled our headcount for 2025. However, we are leaving this form open as an expression of interest since we expect to be growing the team in the future, and we will review your application when we do. As such, you may not hear back on your application to this team until the new year Responsibilities: Design and implement novel data curation pipelines to identify, verify, and filter training data for accuracy given the model’s knowledge Develop specialized classifiers to detect potential hallucinations or miscalibrated claims made by the model Create and maintain comprehensive honesty benchmarks and evaluation frameworks Implement techniques to ground model outputs in verified information, such as search and retrieval-augmented generation (RAG) systems Design and deploy human feedback collection specifically for identifying and correcting miscalibrated responses Design and implement prompting pipelines to generate data that improves model accuracy and honesty Develop and test novel RL environments that reward truthful outputs and penalize fabricated claims Create tools to help human evaluators efficiently assess model outputs for accuracy You may be a good fit if you: Have an MS/PhD in Computer Science, ML, or related field Possess strong programming skills in Python Have industry experience with language model finetuning and classifier training Show proficiency in experimental design and statistical analysis for measuring improvements in calibration and accuracy Care about AI safety and the accuracy and honesty of both current and future AI systems Have experience in data science or the creation and curation of datasets for finetuning LLMs An understanding of various metrics of uncertainty, calibration, and truthfulness in model outputs Strong candidates may also have: Published work on hallucination prevention, factual grounding, or knowledge integration in language models Experience with fact-grounding techniques Background i"
Greenhouse,AI Infrastructure Accounting Lead,anthropic,Finance,,"San Francisco, CA",, 842 ,"aws, azure, gcp, sql",,2025-09-03,https://job-boards.greenhouse.io/anthropic/jobs/4756214008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role Anthropic is seeking an exceptional AI Infrastructure Accounting Lead to join our Corporate Accounting team. In this strategic leadership position, you will build and lead the infrastructure accounting function responsible for managing all aspects of cloud computing, platform infrastructure, and data costs. As we continue our rapid growth, you will ensure operational scalability and financial accuracy of the core functions that enable Anthropic's research and commercial success. You will oversee end-to-end accounting and financial reporting for our largest cost center, working closely with cross-functional teams including Finance, Capacity Planning, and Engineering. You'll develop and implement scalable processes, controls, and systems to support Anthropic's growing financial complexity while providing critical insights that drive strategic decision-making. This is a unique opportunity to have significant impact on a critical aspect of our business as we scale our AI infrastructure. Responsibilities: Lead the team responsible for end-to-end accounting and reporting for AI infrastructure, including compute, cost of revenue, and R&D opex Develop and implement a comprehensive framework for infrastructure cost accounting, ensuring proper classification between Cost of Revenue and Operating Expenses Ensure accurate and timely financial reporting to support strategic decision-making by business leaders Partner with technical teams to understand complex infrastructure requirements and translate them into financial terms Collaborate cross-functionally to improve upstream data pipelines and enhance reporting capabilities Design and scale systems and processes to support Anthropic's growing financial complexity Leverage technical accounting expertise to support the review of complex arrangements, including ASC 842 lease accounting for infrastructure Build and mentor a high-performing team of accounting professionals focused on infrastructure costs Act as the primary liaison with external auditors for compute and infrastructure costs Drive process improvements and automation to enhance efficiency and accuracy of financial reporting Provide strategic insights to leadership on cost optimization opportunities and financial implications of infrastructure decisions You may be a good fit if you: Have 12+ years of progressive experience in accounting, with operational experience at technology companies Hold a Bachelor's degree in Accounting or Finance, CPA or equivalent preferred Have extensive experience managing cloud computing or infrastructure costs in a high-growth technology environment Possess strong technical "
Greenhouse,Customer Success: AI Success Architect (API),anthropic,Sales,,"San Francisco, CA | New York City, NY",,"$200,00",llm,,2025-09-03,https://job-boards.greenhouse.io/anthropic/jobs/4464871008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role As a Customer Success: AI Success Architect (API) at Anthropic, you will be a strategic partner and the go-to technical advisor to our enterprise API customers, helping them harness the full potential of our LLM technology to achieve their business objectives. You'll work with strategic customers by providing technical guidance while driving consumption and optimization of Anthropic's API solutions. Your role focuses on helping customers scale their usage effectively, identify new use cases, and maximize the value of their existing API integrations. Responsibilities: Build trusting, strategic relationships with key customer decision makers Partner with customers to understand their business objectives and technical requirements and guide them toward optimal utilization of Anthropic's API solutions Drive consumption by developing and executing account plans that ground in each customer's business objectives, expand upon use cases that drive toward those objectives, and identify new opportunities for growth Help customers optimize their applications through deeply understanding Anthropic's API capabilities, methodology, and prompting techniques Monitor API usage patterns to mitigate risks, provide recommendations for optimization, and push toward expansion opportunities Lead regular customer stakeholder meetings and quarterly business reviews, focusing on usage patterns, success stories, and growth opportunities Create demonstrations to showcase potential new use cases and capabilities that build upon existing integrations Work cross-functionally with Enterprise Account Executives to identify and pursue expansion opportunities within existing accounts Act as the voice of the customer to Product and Engineering teams, providing detailed feedback on customer needs and feature requirements You may be a good fit if you: 5+ years of experience in technical customer-facing roles (Customer Success, Technical Account Management, Solutions Consultant, or similar) Technical acumen with understanding of APIs, integration concepts, and software development principles Experience explaining and demonstrating technical products to various audiences Understanding of LLMs and AI technologies, with ability to guide customers on optimization best practices Track record of driving technical adoption and consumption in enterprise environments Excellent ability to translate technical concepts for various audiences, from developers to executives Strong project management skills and ability to manage multiple customer relationships Deadline to apply: None. Applications will be reviewed on a rolling basis. The expected salary "
Greenhouse,"Data Scientist, API",anthropic,Data Science & Analytics,,"San Francisco, CA",,"$275,00","aws, llm, python, sql",,2025-09-11,https://job-boards.greenhouse.io/anthropic/jobs/4915058008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role As an early member of our Data Science and Analytics team focusing on our API, you will play a critical role in driving the growth and optimization of Anthropic's API products that power thousands of developers and enterprises building with AI. You'll work at the intersection of product strategy, customer insights, and revenue optimization to help scale our API platform from millions to billions of API calls while maintaining our commitment to safety and reliability. You will partner closely with product, engineering, and go-to-market teams to understand developer and enterprise customer behavior, identify growth opportunities, and drive data-informed decisions that shape our API roadmap. This role offers a unique opportunity to influence how AI is deployed at scale across industries while working with cutting-edge language models and developer tools. Responsibilities: API Product Analytics : Deep dive into API usage patterns, developer adoption funnels, and enterprise customer behavior to provide actionable insights that drive product strategy and feature prioritization Revenue & Retention Analysis : Analyze customer lifecycle metrics, revenue retention patterns, and usage-based billing dynamics to identify opportunities for growth and reduce churn across our API customer base Developer Experience Optimization : Design and analyze experiments to improve API adoption, reduce time-to-value for developers, and enhance the overall developer experience across our platform ecosystem Customer Segmentation & Insights : Build sophisticated models to segment API customers by use case, company size, and behavioral patterns to inform targeted product development and go-to-market strategies Cross-Platform Analysis : Analyze customer behavior across Anthropic's ecosystem (1P API, Bedrock, Vertex AI) to understand platform preferences, switching patterns, and optimization opportunities Experimentation & A/B Testing : Design, execute, and analyze controlled experiments on API features, pricing strategies, and developer onboarding flows to drive measurable improvements in key metrics Predictive Modeling : Develop models to forecast API usage, predict customer growth potential, and identify early signals of expansion or churn risk Enterprise Customer Intelligence : Partner with sales and customer success teams to analyze enterprise customer usage patterns, measure feature adoption, and provide insights that inform account strategy You may be a good fit if you: Have 6+ years of experience in data science or analytics roles, with significant experience in API products, developer tools, or B2B SaaS platforms Have 3+ yea"
Greenhouse,"Data Scientist, Claude Code",anthropic,Data Science & Analytics,,"San Francisco, CA",,"$275,00","python, sql",,2025-09-03,https://job-boards.greenhouse.io/anthropic/jobs/4826091008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role As an early member of our Data Science and Analytics team supporting Claude Code, you will play a critical role in shaping the future of AI-powered developer tools. Claude Code is Anthropic's command line tool that enables developers to delegate coding tasks directly to Claude from their terminal, representing a new frontier in human-AI collaboration for software development. You will be embedded with our Claude Code product team to drive data-informed decision making as we scale this revolutionary developer tool. Working at the intersection of AI capabilities research and product development, you'll help us understand how developers interact with AI coding assistants, measure the impact of our tool on developer productivity, and identify opportunities to enhance the developer experience. This role offers a unique opportunity to influence the development of cutting-edge AI tooling while working with some of the most sophisticated language models in the world. You'll help establish data foundations for a rapidly growing product in the emerging AI-assisted development space. Responsibilities: Deep dive into how developers use Claude Code across different programming languages, project types, and workflows to provide insights that inform product strategy and feature development Design and implement metrics to quantify how Claude Code affects developer productivity, code quality, and development velocity across different use cases and skill levels Analyze patterns in human-AI collaboration within coding workflows, identifying opportunities to improve the handoff between developers and Claude for more effective task delegation Develop hypotheses about product changes, design controlled experiments with developer users, and analyze results to guide feature prioritization and development Identify friction points in the Claude Code user journey and provide data-driven recommendations to improve onboarding, retention, and long-term engagement Build robust measurement frameworks to understand CLI adoption patterns, feature utilization, and user segmentation across different developer personas and organizations Partner with engineering to build experimentation capabilities tailored to developer tools, accounting for the unique challenges of measuring productivity and satisfaction in coding workflows Establish foundational data practices and infrastructure to support rapid iteration and decision-making as the Claude Code product scales You may be a good fit if you: Have 5+ years of experience in data science or analytics roles with significant focus on product analytics Have experience working with developer too"
Greenhouse,"Data Scientist, Platform (Reliability/Latency/Inference)",anthropic,Data Science & Analytics,,"Remote-Friendly (Travel-Required) | San Francisco, CA | Seattle, WA | New York City, NY",,"$275,00","python, sql",,2025-09-03,https://job-boards.greenhouse.io/anthropic/jobs/4801333008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role As an early member of our Data Science team, you will play a crucial role in ensuring our AI systems deliver exceptional user experiences through reliable, low-latency performance. You'll be at the intersection of data science and infrastructure, using rigorous analysis to understand how platform performance impacts user behavior and identifying high-impact opportunities to improve our systems' reliability and responsiveness. Your work will directly influence how millions of users experience Claude and our other AI systems. You'll quantify user sensitivity to latency, reliability, errors, and refusal rates, then translate these insights into actionable recommendations that drive meaningful improvements to our platform infrastructure. This role offers the unique opportunity to shape the technical foundation that enables safe, frontier AI to scale globally. Responsibilities: Design and execute comprehensive analyses to understand how latency, reliability, errors, and refusal rates affect user engagement, satisfaction, and retention across our platform Identify and prioritize high-impact infrastructure improvements by analyzing user behavior patterns, system performance metrics, and the relationship between technical performance and business outcomes Develop robust methodologies to measure platform reliability and performance, including defining key metrics, establishing baselines, and creating monitoring systems that enable proactive optimization Collaborate with engineering teams to design A/B tests and controlled experiments that measure the impact of platform improvements on user experience and system performance Investigate performance anomalies, conduct root cause analysis of reliability issues, and provide data-driven insights to guide engineering priorities and architectural decisions Work closely with Platform Engineering, Product, and Research teams to translate technical performance data into user experience insights and strategic recommendations Build models to forecast platform capacity needs, predict potential reliability issues, and optimize resource allocation to maintain optimal performance at scale Present complex technical analyses and recommendations to both technical and non-technical stakeholders, including engineering leadership and executive teams You may be a good fit if you have: Advanced degree in Statistics, Computer Science, Engineering, Mathematics, or related quantitative field, with 5+ years of hands-on data science experience Deep understanding of distributed systems, cloud infrastructure, and performance engineering, with experience analyzing large-scale system metrics "
Greenhouse,"Engineering Manager, ML Acceleration",anthropic,AI Research & Engineering,,"San Francisco, CA | New York City, NY | Seattle, WA",,"$425,00",,,2025-09-03,https://job-boards.greenhouse.io/anthropic/jobs/4741104008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role: Anthropic’s performance and scaling teams focus on making the most efficient and impactful use of our compute resources, be it inference or training. As an Engineering Manager on these teams you will be responsible for ensuring you and your team are identifying and removing bottlenecks, building robust and durable solutions, and maximizing the efficiency of our systems. You also will help bring clarity, focus, and context to your teams in a fast paced, dynamic environment. Responsibilities: Provide front-line leadership of engineering efforts to improve model performance and scale our inference and training systems Become familiar with the team’s technical stack enough to make targeted contributions as an individual contributor Manage day-to-day execution of the team's work Prioritize the team’s work and manage projects in a highly dynamic, fast paced environment Coach and support your reports in understanding, and pursuing, their professional growth Maintain a deep understanding of the team's technical work and its implications for AI safety You may be a good fit if you: Have 1+ years of management experience in a technical environment, particularly performance or distributed systems Have a background in machine learning, AI, or a similar related technical field Are deeply interested in the potential transformative effects of advanced AI systems and are committed to ensuring their safe development Excel at building strong relationships with stakeholders at all levels Are a quick learner, capable of understanding and contributing to discussions on complex technical topics Have experience managing teams through periods of rapid growth and change Are a quick study: this team sits at the intersection of a large number of different complex technical systems that you’ll need to understand (at a high level of abstraction) to be effective Strong candidates may also have experience with: High performance, large-scale ML systems GPU/Accelerator programming ML framework internals OS internals Language modeling with transformers The expected salary range for this position is: Annual Salary: $425,000 — $560,000 USD Logistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience. Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa,"
Greenhouse,"Machine Learning Engineer, Safeguards",anthropic,Safeguards (Trust & Safety) ,,"San Francisco, CA",,"$340,00","llm, python, pytorch, sql, tensorflow",,2025-09-17,https://job-boards.greenhouse.io/anthropic/jobs/4461625008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role We are looking for ML engineers to help build safety and oversight mechanisms for our AI systems. As a Safeguards Machine Learning Engineer, you will work to train models which detect harmful behaviors and help ensure user well-being. You will apply your technical skills to uphold our principles of safety, transparency, and oversight while enforcing our terms of service and acceptable use policies. Responsibilities: Build machine learning models to detect unwanted or anomalous behaviors from users and API partners, and integrate them into our production system Improve our automated detection and enforcement systems as needed Analyze user reports of inappropriate accounts and build machine learning models to detect similar instances proactively Surface abuse patterns to our research teams to harden models at the training stage You may be a good fit if you: Have 4+ years of experience in a research/ML engineering or an applied research scientist position, preferably with a focus on AI safety. Have proficiency in Python, LLMs, SQL and data analysis/data mining tools. Have proficiency in building safe AI/ML systems, such as behavioral classifiers or anomaly detection. Have strong communication skills and ability to explain complex technical concepts to non-technical stakeholders. Care about the societal impacts and long-term implications of your work. Strong candidates may also have experience with: Machine learning frameworks like Scikit-Learn, TensorFlow, or PyTorch High-performance, large-scale ML systems Language modeling with transformers Reinforcement learning Large-scale ETL The expected salary range for this position is: Annual Salary: $340,000 — $425,000 USD Logistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience. Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to"
Greenhouse,"Machine Learning Systems Engineer, Encodings and Tokenization",anthropic,AI Research & Engineering,,"San Francisco, CA",,"$320,00","llm, python",,2025-09-03,https://job-boards.greenhouse.io/anthropic/jobs/4579552008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the Role We are seeking an experienced Machine Learning Systems Engineer to join our Encodings and Tokenization team at Anthropic. This cross-functional role will be instrumental in developing and optimizing the encodings and tokenization systems used throughout our Finetuning workflows. As a bridge between our Pretraining and Finetuning teams, you'll build critical infrastructure that directly impacts how our models learn from and interpret data. Your work will be foundational to Anthropic's research progress, enabling more efficient and effective training of our AI systems while ensuring they remain reliable, interpretable, and steerable. Responsibilities Design, develop, and maintain tokenization systems used across Pretraining and Finetuning workflows Optimize encoding techniques to improve model training efficiency and performance Collaborate closely with research teams to understand their evolving needs around data representation Build infrastructure that enables researchers to experiment with novel tokenization approaches Implement systems for monitoring and debugging tokenization-related issues in the model training pipeline Create robust testing frameworks to validate tokenization systems across diverse languages and data types Identify and address bottlenecks in data processing pipelines related to tokenization Document systems thoroughly and communicate technical decisions clearly to stakeholders across teams You May Be a Good Fit If You Have significant software engineering experience with demonstrated machine learning expertise Are comfortable navigating ambiguity and developing solutions in rapidly evolving research environments Can work independently while maintaining strong collaboration with cross-functional teams Are results-oriented, with a bias towards flexibility and impact Have experience with machine learning systems, data pipelines, or ML infrastructure Are proficient in Python and familiar with modern ML development practices Have strong analytical skills and can evaluate the impact of engineering changes on research outcomes Pick up slack, even if it goes outside your job description Enjoy pair programming (we love to pair!) Care about the societal impacts of your work and are committed to developing AI responsibly Strong Candidates May Also Have Experience With Working with machine learning data processing pipelines Building or optimizing data encodings for ML applications Implementing or working with BPE, WordPiece, or other tokenization algorithms Performance optimization of ML data processing systems Multi-language tokenization challenges and solutions Research environments where"
Greenhouse,"Machine Learning Systems Engineer, Research Tools",anthropic,AI Research & Engineering,,"San Francisco, CA | New York City, NY",,"$300,00","kubernetes, llm, python",,2025-09-03,https://job-boards.greenhouse.io/anthropic/jobs/4579550008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role: You want to build the cutting-edge systems that train AI models like Claude. You're excited to work at the frontier of machine learning, implementing and improving advanced techniques to create ever more capable, reliable and steerable AI. As an ML Systems Engineer on our Research Tools team, you'll be responsible for the critical algorithms and infrastructure that our researchers depend on to train models. Your work will directly enable breakthroughs in AI capabilities and safety. You'll focus obsessively on improving the performance, robustness, and usability of these systems so our research can progress as quickly as possible. You're energized by the challenge of supporting and empowering our research team in the mission to build beneficial AI systems. Our finetuning researchers train our production Claude models, and internal research models, using RLHF and other related methods. Your job will be to build, maintain, and improve the algorithms and systems that these researchers use to train models. You’ll be responsible for improving the speed, reliability, and ease-of-use of these systems. You may be a good fit if you: Have 2+ years of software engineering experience Like working on systems and tools that make other people more productive Are results-oriented, with a bias towards flexibility and impact Pick up slack, even if it goes outside your job description Enjoy pair programming (we love to pair!) Want to learn more about machine learning research Care about the societal impacts of your work Strong candidates may also have experience with: High performance, large scale distributed systems Kubernetes Python Implementing LLM finetuning algorithms, such as RLHF Representative projects: Profiling our reinforcement learning pipeline to find opportunities for improvement Building a system that regularly launches training jobs in a test environment so that we can quickly detect problems in the training pipeline Making changes to our finetuning systems so they work on new model architectures Building instrumentation to detect and eliminate Python GIL contention in our training code Diagnosing why training runs have started slowing down after some number of steps, and fixing it Implementing a stable, fast version of a new training algorithm proposed by a researcher Deadline to apply: None. Applications will be reviewed on a rolling basis. The expected salary range for this position is: Annual Salary: $300,000 — $405,000 USD Logistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience. Location-based hybrid policy: Currently, we expect all staf"
Greenhouse,"Machine Learning Systems Engineer, RL Engineering",anthropic,AI Research & Engineering,,"San Francisco, CA",,"$300,00","llm, python",,2025-09-03,https://job-boards.greenhouse.io/anthropic/jobs/4577144008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role: You want to build the cutting-edge systems that train AI models like Claude. You're excited to work at the frontier of machine learning, implementing and improving advanced techniques to create ever more capable, reliable and steerable AI. As an ML Systems Engineer on our Reinforcement Learning Engineering team, you'll be responsible for the critical algorithms and infrastructure that our researchers depend on to train models. Your work will directly enable breakthroughs in AI capabilities and safety. You'll focus obsessively on improving the performance, robustness, and usability of these systems so our research can progress as quickly as possible. You're energized by the challenge of supporting and empowering our research team in the mission to build beneficial AI systems. Our finetuning researchers train our production Claude models, and internal research models, using RLHF and other related methods. Your job will be to build, maintain, and improve the algorithms and systems that these researchers use to train models. You’ll be responsible for improving the speed, reliability, and ease-of-use of these systems. You may be a good fit if you: Have 4+ years of software engineering experience Like working on systems and tools that make other people more productive Are results-oriented, with a bias towards flexibility and impact Pick up slack, even if it goes outside your job description Enjoy pair programming (we love to pair!) Want to learn more about machine learning research Care about the societal impacts of your work Strong candidates may also have experience with: High performance, large scale distributed systems Large scale LLM training Python Implementing LLM finetuning algorithms, such as RLHF Representative projects: Profiling our reinforcement learning pipeline to find opportunities for improvement Building a system that regularly launches training jobs in a test environment so that we can quickly detect problems in the training pipeline Making changes to our finetuning systems so they work on new model architectures Building instrumentation to detect and eliminate Python GIL contention in our training code Diagnosing why training runs have started slowing down after some number of steps, and fixing it Implementing a stable, fast version of a new training algorithm proposed by a researcher Deadline to apply: None. Applications will be reviewed on a rolling basis. The expected salary range for this position is: Annual Salary: $300,000 — $405,000 USD Logistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience. Location-based hybrid pol"
Greenhouse,"Machine Learning Systems Engineer, Safeguards Research",anthropic,AI Research & Engineering,,"San Francisco, CA",,"$315,00","jax, llm, python, pytorch, tensorflow",,2025-09-03,https://job-boards.greenhouse.io/anthropic/jobs/4613882008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role The Safeguards Research Team (part of the larger Alignment Science team ) conducts critical safety research and engineering to ensure AI systems can be deployed safely. Our work is fundamental to Anthropic's ability to release advanced models—without the safety systems we build, models like Claude Opus 4 simply couldn't be deployed. We're not just another ML team; we work at the frontier of AI safety, directly enabling Anthropic to fulfill its Responsible Scaling Policy commitments. As a Machine Learning Engineer on our team, you'll bridge the gap between research and engineering, developing robust end-to-end pipelines and ML systems that directly support our safety initiatives. You'll work on building scalable infrastructure for evaluating safety systems, implementing efficient training pipelines for safeguards, and creating automated systems to help us understand and mitigate risks in advanced AI systems. Your applied ML engineering work will have immediate, measurable impact—determining whether Anthropic can release its next generation of models while maintaining our safety guarantees. You bring both ML fundamentals and strong engineering practices to the team. You're comfortable training and fine-tuning language models, have intuitions about hyperparameter optimization, and can implement efficient data processing pipelines. You take a pragmatic approach to ML engineering, preferring simple, effective solutions over complex ones. You'll collaborate closely with researchers to translate experimental concepts into production-quality ML systems that address both immediate safety challenges and support longer-term research initiatives. Representative projects: Design and implement ML pipelines for training and evaluating safety classifiers and detection models Build infrastructure for hyperparameter optimization and model selection across safety experiments Create flexible interfaces and dashboards for researchers to interact with models and experimental setups Create efficient data processing pipelines that can handle large-scale model outputs and training datasets Develop tooling to automate the generation, analysis, and classification of jailbreak attempts You may be a good fit if you: Understand fundamental ML concepts like overfitting and regularization Have practical experience with improving and evaluating ML models Are proficient with ML frameworks (e.g., PyTorch, TensorFlow, JAX) and can implement custom training loops Have strong software engineering skills, particularly with Python Excel at building scalable data pipelines, interpretable dashboards, and ML infrastructure Are experienced wit"
Greenhouse,"Manager of Solutions Architecture, Applied AI",anthropic,Sales,,"San Francisco, CA | New York City, NY",,"$270,00",llm,,2025-09-03,https://job-boards.greenhouse.io/anthropic/jobs/4819732008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role: As the manager of the Digital Native, Applied AI, Solutions Architect team at Anthropic, you will drive the adoption of frontier AI by enabling the deployment of Anthropic's products (Claude for Enterprise, Claude Code, and API) across Enterprise Tech companies and digital-first organizations. You'll leverage your technical skills and consultative sales experience to drive positive AI transformation that addresses our customers' business needs, meets their technical requirements, and provides a high degree of reliability and safety. You'll be responsible for leading & growing the Digital Native, Applied AI, Solutions Architect team, establish processes and best practices for your segment's pre-sales engagements based on your years of experience, help each team member achieve success, high productivity, and career growth, and represent Anthropic as a technical lead on some of its most important partnerships. In collaboration with the Sales, Product, and Engineering teams, you'll help enterprise tech partners incorporate leading-edge AI systems into their cutting-edge products and platforms. You will employ your excellent communication skills to explain and demonstrate complex solutions persuasively to technical and non-technical audiences alike. You will play a critical role in identifying opportunities to innovate and differentiate our AI systems, while maintaining our best-in-class safety standards. Responsibilities: Manage and mentor a team of Applied AI, Solutions Architects, providing both technical guidance and career development Set goals and reviews for your team, promoting growth and output Work with a handful of highest-value Digital Native enterprise customers on their overall AI adoption strategies, focusing on pre-sales technical excellence including use case scoping, technical champion building, and POC execution Partner closely with your aligned GTM leadership to understand customer requirements & co-build GTM strategies to drive adoption for Digital Native enterprise customers Own the technical portions of pre-sales engagements, ensuring your team provides compelling demos and validates enterprise customer ROI from Anthropic products Drive collaboration from cross-functional teams to influence and unify stakeholders at all levels of the organization to drive business outcomes Travel occasionally to customer sites for executive-level sessions, technical workshops, and building relationships Establish a shared vision for creating solutions that enable beneficial and safe AI in technology products Lead the vision, strategy, and execution of innovative solutions that leverage our latest m"
Greenhouse,"ML Infrastructure Engineer, Safeguards",anthropic,Safeguards (Trust & Safety) ,,"San Francisco, CA",,"$320,00","aws, gcp, jax, kubernetes, llm, python, pytorch, spark, tensorflow",,2025-09-03,https://job-boards.greenhouse.io/anthropic/jobs/4778843008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role We are seeking a Machine Learning Infrastructure Engineer to join our Safeguards organization, where you'll build and scale the critical infrastructure that powers our AI safety systems. You'll work at the intersection of machine learning, large-scale distributed systems, and AI safety, developing the platforms and tools that enable our safeguards to operate reliably at scale. As part of the Safeguards team, you'll design and implement ML infrastructure that powers Claude safety. Your work will directly contribute to making AI systems more trustworthy and aligned with human values, ensuring our models operate safely as they become more capable. Responsibilities: Design and build scalable ML infrastructure to support real-time and batch classifier and safety evaluations across our model ecosystem Build monitoring and observability tools to track model performance, data quality, and system health for safety-critical applications Collaborate with research teams to productionize safety research, translating experimental safety techniques into robust, scalable systems Optimize inference latency and throughput for real-time safety evaluations while maintaining high reliability standards Implement automated testing, deployment, and rollback systems for ML models in production safety applications Partner with Safeguards, Security, and Alignment teams to understand requirements and deliver infrastructure that meets safety and production needs Contribute to the development of internal tools and frameworks that accelerate safety research and deployment You may be a good fit if you: Have 5+ years of experience building production ML infrastructure, ideally in safety-critical domains like fraud detection, content moderation, or risk assessment Are proficient in Python and have experience with ML frameworks like PyTorch, TensorFlow, or JAX Have hands-on experience with cloud platforms (AWS, GCP) and container orchestration (Kubernetes) Understand distributed systems principles and have built systems that handle high-throughput, low-latency workloads Have experience with data engineering tools and building robust data pipelines (e.g., Spark, Airflow, streaming systems) Are results-oriented, with a bias towards reliability and impact in safety-critical systems Enjoy collaborating with researchers and translating cutting-edge research into production systems Care deeply about AI safety and the societal impacts of your work Strong candidates may have experience with: Working with large language models and modern transformer architectures Implementing A/B testing frameworks and experimentation infrastructure for ML sys"
Greenhouse,"Product Engineer, Applied AI",anthropic,Sales,,"Tokyo, Japan",, 25,"llm, python",,2025-09-09,https://job-boards.greenhouse.io/anthropic/jobs/4830207008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role As a member of the Applied AI team at Anthropic, you will drive the adoption of frontier AI by developing bespoke LLM solutions for top enterprises across Japan. You’ll leverage your customer-facing experience and technical skills to architect innovative solutions that address our customers' business needs, meet their technical requirements, and provide a high degree of reliability and safety. In collaboration with the Sales, Product, and Engineering teams, you’ll help enterprise partners incorporate leading-edge AI systems into their products. You will employ your excellent communication skills to explain and demonstrate complex solutions persuasively to technical and non-technical audiences alike. You will play a critical role in identifying opportunities to innovate and differentiate our AI systems, while maintaining our best-in-class safety standards. Responsibilities: Act as the primary technical advisor for prospective customers across Japan evaluating Claude. Demonstrate how Claude can be used to solve high value business problems by developing system architectures and leveraging novel prompting techniques Partner closely with account executives to understand customer requirements. Configure Claude's capabilities to showcase how it meets the customer's needs. Develop customized pilots and prototypes, as well as evaluation suites to make the case for customer adoption Drive technical decision making by advising on optimal setup, architecture, and integration of Claude into the customer's existing infrastructure Recommend solutions to technical roadblocks Support customer onboarding across Japan by working cross-functionally to ensure successful ramp and adoption. Serve as an ongoing technical advisor throughout implementation and beyond go-live Travel occasionally to customer sites for workshops, implementation support, and building relationships Establish a shared vision for creating solutions that enable beneficial and safe AI Lead the vision, strategy, and execution of innovative solutions that leverage our latest models’ capabilities across Japan You may be a good fit if you have: 4+ years of experience as a Technical Product Manager, Forward Deployed Engineer, or Platform Engineer Native-level Japanese fluency and business-level English required Designed novel and innovative solutions for technical platforms in a developing business area across Japan Strong technical aptitude to partner with engineers and strong proficiency in Python required Recent experience building production systems with large language models The ability to navigate and execute amidst ambiguity, and to flex into diffe"
Greenhouse,"Product Engineer, Applied AI",anthropic,Sales,,"San Francisco, CA | New York City, NY | Seattle, WA",,"$200,00","llm, python",,2025-09-17,https://job-boards.greenhouse.io/anthropic/jobs/4461430008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. As a member of the Applied AI team at Anthropic, you will be a technical Product Engineer focused on becoming a trusted technical advisor to customers as they adopt Claude. You will work closely with customer product and engineering teams as they ship new products powered by Claude: advising on architecture design decisions, developing evaluation frameworks, and guiding customers through the most cutting edge implementation patterns for LLMs. Working closely with our Sales, Product, and Engineering teams, you'll guide customers from technical discovery through successful deployment. You'll combine deep engineering expertise with customer-facing skills to help customers understand the potential of working with LLMs and build innovative solutions that address complex business challenges while maintaining our high standards for safety and reliability. Responsibilities: Serve as a technical advisor to Anthropic customers as they deploy new products & workflows with our models: from discovery through deployment, coordinating internally across multiple teams to drive customer success Partner with account executives to deeply understand customer product requirements and architect technical solutions, ensuring alignment between business objectives and technical implementation Guide technical architecture decisions and help customers build state-of-the-art products & workflows with LLMs via API Develop customized pilots, prototypes, and evaluation suites that make the case for customer deployment of our models into customer products and workflows via our API Lead hands-on technical workshops and code reviews with customer engineering teams Identify common design patterns and contribute insights back to our Product and Engineering teams Maintain strong knowledge of the latest developments in LLM capabilities, implementation patterns, and AI product development stacks Travel occasionally to customer sites for workshops, implementation support, and building relationships Attend conferences, lead speaking engagements, write blog posts and white papers on topics surrounding the AI space You may be a good fit if you have: 4+ years of experience in a technical roles such as Customer Engineer, Forward Deployed Engineer, Software Engineer or Technical Product Manager with a desire to work closely with customers Production experience with LLMs including advanced prompt engineering, agent development, evaluation frameworks, and deployment at scale Strong programming skills with proficiency in Python and experience building production applications Expertise working with common LLM implementation patterns, prompt engineering, evaluation"
Greenhouse,"Recruiter, AI Research",anthropic,People,,"San Francisco, CA",,"$170,00",llm,,2025-09-03,https://job-boards.greenhouse.io/anthropic/jobs/4604015008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the Role: Anthropic is looking for a talented AI Research Recruiter to partner with our Research teams. In this pivotal role, you will be instrumental in shaping the future of our organization by identifying, engaging, and hiring the best and brightest minds across a range of disciplines. As we continue to push the boundaries of AI research and development, we need a passionate recruiter who can help us build a world-class team dedicated to creating safe and beneficial AI systems. Responsibilities: Develop and execute strategic recruiting plans to identify, source, and hire highly qualified candidates, with a focus on Machine Learning and AI research talent Partner with Research hiring managers and interviewers to understand hiring needs, team matching, required skills and qualifications Enhance and implement recruiting processes and programs while maintaining an inclusive and high talent bar, such as developing targeted outreach campaigns, building connections with industry leaders, and removing any unfair biases from the hiring process Collaborate with leadership and cross-functional partners to understand organizational needs and map out long-term talent acquisition strategies that balance priorities across all technical teams Enhance Anthropic's employer brand within the research and science community to showcase our mission, culture, and values to candidates Stay up-to-date on recruiting best practices, emerging sourcing techniques, interview innovations, and workplace trends You may be a good fit if you: Have 5+ years of experience in full life cycle recruiting supporting technical research teams Have a passion for AI's potential to positively impact the world and realistic assessment of its risks and limitations Are experimental and are open to new, creative recruiting ideas, or have experience working with hiring managers who are open to non-traditional talent strategies Thrive in fast-paced, dynamic environments and enjoy juggling multiple priorities Possess strong technical aptitude with the ability to understand and evaluate technical qualifications Have enthusiasm for deeply understanding the needs of researchers and innovating on recruiting processes to make them more tailored to the world of research Have excellent organizational skills and attention to detail, as well as a proactive mindset and ability to operate with autonomy Have experience partnering with researchers and hiring talent that work on GenAI and LLMs Have a proven track record of scaling and building diverse and high-performing teams in a fast-paced, high-growth startup environment Strong candidates may also: Bring a deep interes"
Greenhouse,"Research Engineer / Research Scientist, Multimodal",anthropic,AI Research & Engineering,,"London, UK",,"£250,00","kubernetes, pytorch",,2025-09-03,https://job-boards.greenhouse.io/anthropic/jobs/4629430008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. At Anthropic, we believe the most impactful safety research will require access to frontier AI systems. The most powerful AIs will operate not just on text but also other modes of data, including images, video and audio. Such models have potential to augment human creativity and productivity in exciting ways. However, we are very concerned about the risks introduced by powerful multimodal AIs. The Multimodal team at Anthropic builds and studies multimodal models to better understand and mitigate these risks. Our team works across many parts of a large stack that includes training, inference, system design and data collection. Some of our core focus areas are: Foundational Research We develop new architectures for modeling multimodal data and study how they interact with text-only models at scale. Building Infrastructure We work on many infrastructure projects including: Complex multimodal reinforcement learning environments. High-performance RPC servers for processing image inputs. Sandboxing infrastructure for securely collecting data. Data Ingestion We are more interested in running simple experiments at large scale than smaller complex experiments. This requires access to very large sources of multimodal data. We develop tooling to collect, process and clean multimodal data at scale. Because we focus on so many areas, the team is looking to work with both experienced engineers and strong researchers, and encourage anyone along the researcher/engineer curve to apply. You may be a good fit if you: Have significant software engineering experience Are results-oriented, with a bias towards flexibility and impact Pick up slack, even if it goes outside your job description Enjoy pair programming (we love to pair!) Want to learn more about machine learning research Care about the societal impacts of your work Strong candidates may also have experience with: High performance, large-scale ML systems GPUs, Kubernetes, Pytorch, or OS internals Language modeling with transformers Reinforcement learning Large-scale ETL The expected salary range for this position is: Annual Salary: £250,000 — £270,000 GBP Logistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience. Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigrat"
Greenhouse,"Research Engineer / Research Scientist, Pre-training",anthropic,AI Research & Engineering,,"Zürich, CH",, 25,"kubernetes, llm, python",,2025-09-03,https://job-boards.greenhouse.io/anthropic/jobs/4799425008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the team We are seeking passionate Research Scientists and Engineers to join our growing Pre-training team in Zurich. We are involved in developing the next generation of large language models. The team primarily focuses on multimodal capabilities: giving LLMs the ability to understand and interact with modalities other than text. In this role, you will work at the intersection of cutting-edge research and practical engineering, contributing to the development of safe, steerable, and trustworthy AI systems. Responsibilities In this role you will interact with many parts of the engineering and research stacks. Conduct research and implement solutions in areas such as model architecture, algorithms, data processing, and optimizer development Independently lead small research projects while collaborating with team members on larger initiatives Design, run, and analyze scientific experiments to advance our understanding of large language models Optimize and scale our training infrastructure to improve efficiency and reliability Develop and improve dev tooling to enhance team productivity Contribute to the entire stack, from low-level optimizations to high-level model design Qualifications & Experience We encourage you to apply even if you do not believe you meet every single criterion. Because we focus on so many areas, the team is looking for both experienced engineers and strong researchers, and encourage anyone along the researcher/engineer spectrum to apply. Degree (BA required, MS or PhD preferred) in Computer Science, Machine Learning, or a related field Strong software engineering skills with a proven track record of building complex systems Expertise in Python and deep learning frameworks Have worked on high-performance, large-scale ML systems, particularly in the context of language modeling Familiarity with ML Accelerators, Kubernetes, and large-scale data processing Strong problem-solving skills and a results-oriented mindset Excellent communication skills and ability to work in a collaborative environment You'll thrive in this role if you Have significant software engineering experience Are able to balance research goals with practical engineering constraints Are happy to take on tasks outside your job description to support the team Enjoy pair programming and collaborative work Are eager to learn more about machine learning research Are enthusiastic to work at an organization that functions as a single, cohesive team pursuing large-scale AI research projects Have ambitious goals for AI safety and general progress in the next few years, and you’re excited to create the best outcomes over the long-term"
Greenhouse,"Research Scientist / Research Engineer, Pre-training",anthropic,AI Research & Engineering,,"London, UK",,"£250,00","kubernetes, llm, python, pytorch",,2025-09-03,https://job-boards.greenhouse.io/anthropic/jobs/4681526008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. Anthropic is at the forefront of AI research, dedicated to developing safe, ethical, and powerful artificial intelligence. Our mission is to ensure that transformative AI systems are aligned with human interests. We are seeking a Research Engineer to join our Pretraining team, responsible for developing the next generation of large language models. In this role, you will work at the intersection of cutting-edge research and practical engineering, contributing to the development of safe, steerable, and trustworthy AI systems. Key Responsibilities: Conduct research and implement solutions in areas such as model architecture, algorithms, data processing, and optimizer development Independently lead small research projects while collaborating with team members on larger initiatives Design, run, and analyze scientific experiments to advance our understanding of large language models Optimize and scale our training infrastructure to improve efficiency and reliability Develop and improve dev tooling to enhance team productivity Contribute to the entire stack, from low-level optimizations to high-level model design Qualifications: Advanced degree (MS or PhD) in Computer Science, Machine Learning, or a related field Strong software engineering skills with a proven track record of building complex systems Expertise in Python and experience with deep learning frameworks (PyTorch preferred) Familiarity with large-scale machine learning, particularly in the context of language models Ability to balance research goals with practical engineering constraints Strong problem-solving skills and a results-oriented mindset Excellent communication skills and ability to work in a collaborative environment Care about the societal impacts of your work Preferred Experience: Work on high-performance, large-scale ML systems Familiarity with GPUs, Kubernetes, and OS internals Experience with language modeling using transformer architectures Knowledge of reinforcement learning techniques Background in large-scale ETL processes You'll thrive in this role if you: Have significant software engineering experience Are results-oriented with a bias towards flexibility and impact Willingly take on tasks outside your job description to support the team Enjoy pair programming and collaborative work Are eager to learn more about machine learning research Are enthusiastic to work at an organization that functions as a single, cohesive team pursuing large-scale AI research projects Are working to align state of the art models with human values and preferences, understand and interpret deep neural networks, or develop new models to support these areas of res"
Greenhouse,"Research Scientist, Interpretability",anthropic,AI Research & Engineering,,"San Francisco, CA",remote, 2023 ,"llm, python",,2025-09-03,https://job-boards.greenhouse.io/anthropic/jobs/4020159008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role: When you see what modern language models are capable of, do you wonder, ""How do these things work? How can we trust them?"" The Interpretability team at Anthropic is working to reverse-engineer how trained models work because we believe that a mechanistic understanding is the most robust way to make advanced systems safe. We’re looking for researchers and engineers to join our efforts. People mean many different things by ""interpretability"". We're focused on mechanistic interpretability, which aims to discover how neural network parameters map to meaningful algorithms. Some useful analogies might be to think of us as trying to do ""biology"" or ""neuroscience"" of neural networks using “microscopes” we build, or as treating neural networks as binary computer programs we're trying to ""reverse engineer"". A few places to learn more about our work and team at a high level are this introduction to Interpretability from our research lead, Chris Olah ; a discussion of our work on the Hard Fork podcast produced by the New York Times, and this blog post (and accompanying video) sharing more about some of the engineering challenges we’d had to solve to get these results. Some of our team's notable publications include A Mathematical Framework for Transformer Circuits , In-context Learning and Induction Heads , Toy Models of Superposition , Scaling Monosemanticity , and our Circuits’ Methods and Biology papers. This work builds on ideas from members' work prior to Anthropic such as the original circuits thread , Multimodal Neurons , Activation Atlases , and Building Blocks . We aim to create a solid foundation for mechanistically understanding neural networks and making them safe (see our vision post ). In the short term, we have focused on resolving the issue of ""superposition"" (see Toy Models of Superposition , Superposition, Memorization, and Double Descent , and our May 2023 update ), which causes the computational units of the models, like neurons and attention heads, to be individually uninterpretable, and on finding ways to decompose models into more interpretable components. Our subsequent work found millions of features in Sonnet, one of our production language models, represents progress in this direction. In our most recent work, we develop methods that allow us to build circuits using features and use this circuits to understand the mechanisms associated with a model's computation and study specific examples of multi-hop reasoning, planning, and chain-of-thought faithfulness on Haiku 3.5, one of our production models.” This is a stepping stone towards our overall goal of mechanistically understanding ne"
Greenhouse,"Research Scientist, Tokens (Multimodal)",anthropic,AI Research & Engineering,,"San Francisco, CA | New York City, NY | Seattle, WA",,"$280,00","kubernetes, pytorch",,2025-09-03,https://job-boards.greenhouse.io/anthropic/jobs/4628787008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. At Anthropic, we believe the most impactful safety research will require access to frontier AI systems. The most powerful AIs will operate not just on text but also other modes of data, including images, video and audio. Such models have potential to augment human creativity and productivity in exciting ways. However, we are very concerned about the risks introduced by powerful multimodal AIs. The Multimodal team at Anthropic builds and studies multimodal models to better understand and mitigate these risks. Our team works across many parts of a large stack that includes training, inference, system design and data collection. Some of our core focus areas are: Foundational Research We develop new architectures for modeling multimodal data and study how they interact with text-only models at scale. Building Infrastructure We work on many infrastructure projects including: Complex multimodal reinforcement learning environments. High-performance RPC servers for processing image inputs. Sandboxing infrastructure for securely collecting data. Data Ingestion We are more interested in running simple experiments at large scale than smaller complex experiments. This requires access to very large sources of multimodal data. We develop tooling to collect, process and clean multimodal data at scale. Because we focus on so many areas, the team is looking to work with both experienced engineers and strong researchers, and encourage anyone along the researcher/engineer curve to apply. You may be a good fit if you: Have significant software engineering experience Are results-oriented, with a bias towards flexibility and impact Pick up slack, even if it goes outside your job description Enjoy pair programming (we love to pair!) Want to learn more about machine learning research Care about the societal impacts of your work Strong candidates may also have experience with: High performance, large-scale ML systems GPUs, Kubernetes, Pytorch, or OS internals Language modeling with transformers Reinforcement learning Large-scale ETL The expected salary range for this position is: Annual Salary: $280,000 — $425,000 USD Logistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience. Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigrat"
Greenhouse,"Software Engineer, AI Reliability Engineering",anthropic,AI Research & Engineering,,"Dublin, IE",,1000 ,llm,,2025-09-04,https://job-boards.greenhouse.io/anthropic/jobs/4608196008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role Anthropic is seeking talented and experienced Reliability Engineers, including Software Engineers and Systems Engineers with experience and interest in reliability, to join our team. We will be defining and achieving reliability metrics for all of Anthropic’s internal and external products and services. While significantly improving reliability for Anthropic’s services, we plan to use the developing capabilities of modern AI models to reengineer the way we work. This team will be a critical part of Anthropic’s mission to bring the capabilities of groundbreaking AI technologies to benefit humanity in a safe and reliable way. Responsibilities: Develop appropriate Service Level Objectives for large language model serving and training systems, balancing availability/latency with development velocity Design and implement monitoring systems including availability, latency and other salient metrics Assist in the design and implementation of high-availability language model serving infrastructure capable of handling the needs of millions of external customers and high-traffic internal workloads Develop and manage automated failover and recovery systems for model serving deployments across multiple regions and cloud providers Lead incident response for critical AI services, ensuring rapid recovery and systematic improvements from each incident Build and maintain cost optimization systems for large-scale AI infrastructure, focusing on accelerator (GPU/TPU/Trainium) utilization and efficiency You may be a good fit if you: Have extensive experience with distributed systems observability and monitoring at scale Understand the unique challenges of operating AI infrastructure, including model serving, batch inference, and training pipelines Have proven experience implementing and maintaining SLO/SLA frameworks for business-critical services Are comfortable working with both traditional metrics (latency, availability) and AI-specific metrics (model performance, training convergence) Have experience with chaos engineering and systematic resilience testing Can effectively bridge the gap between ML engineers and infrastructure teams Have excellent communication skills Strong candidates may also: Have experience operating large-scale model training infrastructure or serving infrastructure (>1000 GPUs) Have experience with one or more ML hardware accelerators (GPUs, TPUs, Trainium, e.g.) Understand ML-specific networking optimizations like RDMA and InfiniBand Have expertise in AI-specific observability tools and frameworks Understand ML model deployment strategies and their reliability implications Have contributed to op"
Greenhouse,"Solutions Architect, Applied AI",anthropic,Sales,,"Tokyo, Japan",, 25,"llm, python",,2025-09-09,https://job-boards.greenhouse.io/anthropic/jobs/4858547008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role As an Applied AI team member at Anthropic, you will be a Pre-Sales architect focused on becoming a trusted technical advisor helping large enterprises understand the value of Claude and paint the vision on how they can successfully integrate and deploy Claude into their technology stack. You'll combine your deep technical expertise with customer-facing skills to architect innovative LLM solutions that address complex business challenges while maintaining our high standards for safety and reliability. Working closely with our Sales, Product, and Engineering teams, you'll guide customers from initial technical discovery through successful deployment. You'll leverage your expertise to help customers understand Claude's capabilities, develop evals, and design scalable architectures that maximize the value of our AI systems. Responsibilities: Partner with account executives across Japan to deeply understand customer requirements and translate them into technical solutions, ensuring alignment between business objectives and technical implementation Serve as the primary technical advisor to enterprise customers across Japan throughout their Claude adoption journey, from discovery to initial evaluation through deployment. You will need to coordinate internally across multiple teams & stakeholders to drive customer success Support customers building with both the Claude API and Claude for Work Create and deliver compelling technical content tailored to different audiences across Japan. You will need to be able to spread the gamut from technical deep dives for engineering & development teams up to business value focused conversations with executives Guide technical architecture decisions and help customers across Japan integrate Claude effectively into their existing technology stack Help customers develop evaluation frameworks to measure Claude's performance for their specific use cases Identify common integration patterns and contribute insights back to our Product and Engineering teams Travel occasionally to customer sites for workshops, technical deep dives, and relationship building Maintain strong knowledge of the latest developments in LLM capabilities and implementation patterns You may be a good fit if you have: 5+ years of experience in technical customer-facing roles such as Solutions Architect, Sales Engineer, or Technical Account Manager Native-level Japanese fluency and business-level English required Experience working with enterprise customers, navigating complex buying cycles involving multiple stakeholders Exceptional ability to build relationships with and communicate technical concepts to d"
Greenhouse,"Solutions Architect, Applied AI",anthropic,Sales,,"San Francisco, CA | New York City, NY | Seattle, WA",,"$240,00","llm, python",,2025-09-03,https://job-boards.greenhouse.io/anthropic/jobs/4461444008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role As an Applied AI team member at Anthropic, you will be a Pre-Sales architect focused on becoming a trusted technical advisor helping large enterprises understand the value of Claude and paint the vision on how they can successfully integrate and deploy Claude into their technology stack. You'll combine your deep technical expertise with customer-facing skills to architect innovative LLM solutions that address complex business challenges while maintaining our high standards for safety and reliability. Working closely with our Sales, Product, and Engineering teams, you'll guide customers from initial technical discovery through successful deployment. You'll leverage your expertise to help customers understand Claude's capabilities, develop evals, and design scalable architectures that maximize the value of our AI systems. Responsibilities: Partner with account executives to deeply understand customer requirements and translate them into technical solutions, ensuring alignment between business objectives and technical implementation Serve as the primary technical advisor to enterprise customers throughout their Claude adoption journey, from discovery to initial evaluation through deployment. You will need to coordinate internally across multiple teams & stakeholders to drive customer success Support customers building with both the Claude API and Claude for Work Create and deliver compelling technical content tailored to different audiences. You will need to be able to spread the gamut from technical deep dives for engineering & development teams up to business value focused conversations with executives Guide technical architecture decisions and help customers integrate Claude effectively into their existing technology stack Help customers develop evaluation frameworks to measure Claude's performance for their specific use cases Identify common integration patterns and contribute insights back to our Product and Engineering teams Travel occasionally to customer sites for workshops, technical deep dives, and relationship building Maintain strong knowledge of the latest developments in LLM capabilities and implementation patterns You may be a good fit if you have: 5+ years of experience in technical customer-facing roles such as Solutions Architect, Sales Engineer, or Technical Account Manager Experience working with enterprise customers, navigating complex buying cycles involving multiple stakeholders Exceptional ability to build relationships with and communicate technical concepts to diverse stakeholders to include C-suite executives, engineering & IT teams, and more Strong technical communication ski"
Greenhouse,"Solutions Architect, Applied AI",anthropic,Sales,,"London, UK",,"£105,00","llm, python",,2025-09-03,https://job-boards.greenhouse.io/anthropic/jobs/4819502008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role As an Applied AI team member at Anthropic, you will be a Pre-Sales architect focused on becoming a trusted technical advisor helping large enterprises understand the value of Claude and paint the vision on how they can successfully integrate and deploy Claude into their technology stack. You'll combine your deep technical expertise with customer-facing skills to architect innovative LLM solutions that address complex business challenges while maintaining our high standards for safety and reliability. Working closely with our Sales, Product, and Engineering teams, you'll guide customers from initial technical discovery through successful deployment. You'll leverage your expertise to help customers understand Claude's capabilities, develop evals, and design scalable architectures that maximize the value of our AI systems. Responsibilities: Partner with account executives to deeply understand customer requirements and translate them into technical solutions, ensuring alignment between business objectives and technical implementation Serve as the primary technical advisor to enterprise customers throughout their Claude adoption journey, from discovery to initial evaluation through deployment. You will need to coordinate internally across multiple teams & stakeholders to drive customer success Support customers building with both the Claude API and Claude for Work Create and deliver compelling technical content tailored to different audiences. You will need to be able to spread the gamut from technical deep dives for engineering & development teams up to business value focused conversations with executives Guide technical architecture decisions and help customers integrate Claude effectively into their existing technology stack Help customers develop evaluation frameworks to measure Claude's performance for their specific use cases Identify common integration patterns and contribute insights back to our Product and Engineering teams Travel occasionally to customer sites for workshops, technical deep dives, and relationship building Maintain strong knowledge of the latest developments in LLM capabilities and implementation patterns You may be a good fit if you have: 5+ years of experience in technical customer-facing roles such as Solutions Architect, Sales Engineer, or Technical Account Manager Experience working with enterprise customers, navigating complex buying cycles involving multiple stakeholders Exceptional ability to build relationships with and communicate technical concepts to diverse stakeholders to include C-suite executives, engineering & IT teams, and more Strong technical communication ski"
Greenhouse,"Tech Lead Manager, Safeguards ML Infrastructure",anthropic,Safeguards (Trust & Safety) ,,"San Francisco, CA",,"$405,00",llm,,2025-09-12,https://job-boards.greenhouse.io/anthropic/jobs/4778852008,"About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role Anthropic is seeking an ML Infrastructure Engineering Manager to lead a critical team within our Safeguards organization. You'll manage and grow a team of infrastructure engineers who build and scale the foundational systems that power our AI safety and trust mechanisms. This role combines deep technical leadership in ML infrastructure with people management, driving both the strategic vision and day-to-day execution of systems that ensure our AI models operate safely and reliably at scale. Your team will be responsible for the infrastructure backbone that enables real-time safety evaluations and systems to make Claude safe You'll work closely with research teams to translate cutting-edge safety research into production-ready systems, while partnering with Safeguards, Security, and Alignment teams to ensure our infrastructure meets the demanding requirements of safety-critical applications. Responsibilities: Set team vision and roadmap for ML infrastructure that powers Anthropic's safety and trust systems, ensuring scalability, reliability, and performance at production scale Lead a team of ML infrastructure and software engineers to build robust platforms supporting real-time safety evaluations, feature stores, model serving, and data pipelines Partner with Safeguards, Security, Research, and Product teams to identify infrastructure requirements and translate complex safety research into scalable production systems Drive technical strategy for ML infrastructure architecture, making key decisions about technology choices, system design, and platform evolution Maintain deep technical expertise in ML infrastructure, distributed systems, and safety-critical applications to provide technical leadership and guidance Hire, support, and develop team members through continuous feedback, career coaching, and people management practices Collaborate across teams to ensure infrastructure supports rapid experimentation while maintaining production reliability and safety standards Champion engineering best practices including automated testing, deployment pipelines, monitoring, and incident response for safety-critical systems You may be a good fit if you: Have 4+ years of management experience leading technical teams focused on LLM infrastructure, platform engineering, or distributed systems Have 8+ years of hands-on experience building production ML infrastructure, ideally in safety-critical domains like fraud detection, content moderation, or risk assessment Demonstrated ability to lead and manage high-performing technical teams through periods of rapid growth and scaling challenges Possess deep technical knowl"
Greenhouse,AI Engineer - FDE (Forward Deployed Engineer),databricks,Professional Services Operations,,Remote - India,remote,326,"aws, azure, databricks, gcp, pytorch, rag, spark",,2025-09-11,https://databricks.com/company/careers/open-positions/job?gh_jid=8099751002,"CSQ326R35 Mission The AI Forward Deployed Engineering (AI FDE) team is a highly specialized customer-facing AI team at Databricks. We deliver professional services engagements to help our customers build and productionize first-of-its-kind AI applications. We work cross-functionally to shape long-term strategic priorities and initiatives alongside engineering, product, and developer relations, as well as support internal subject matter expert (SME) teams. We view our team as an ensemble: we look for individuals with strong, unique specializations to improve the overall strength of the team. This team is the right fit for you if you love working with customers, teammates, and fueling your curiosity for the latest trends in GenAI, LLMOps, and ML more broadly. This role can be remote. The impact you will have: Develop cutting-edge GenAI solutions, incorporating the latest techniques from our Mosaic AI research to solve customer problems Own production rollouts of consumer and internally facing GenAI applications Serve as a trusted technical advisor to customers across a variety of domains Present at conferences such as Data + AI Summit, recognized as a thought leader internally and externally Collaborate cross-functionally with the product and engineering teams to influence priorities and shape the product roadmap What we look for: Experience building GenAI applications, including RAG, multi-agent systems, Text2SQL, fine-tuning, etc., with tools such as HuggingFace, LangChain, and DSPy Minimum of 5+ years of relevant experience as a Data Scientist preferably working in a consulting role Expertise in deploying production-grade GenAI applications, including evaluation and optimizations Extensive years of hands-on industry data science experience, leveraging common machine learning and data science tools, i.e. pandas, scikit-learn, PyTorch, etc. Experience building production-grade machine learning deployments on AWS, Azure, or GCP Graduate degree in a quantitative discipline (Computer Science, Engineering, Statistics, Operations Research, etc.) or equivalent practical experience Experience communicating and/or teaching technical concepts to non-technical and technical audiences alike Passion for collaboration, life-long learning, and driving business value through AI [Preferred] Experience using the Databricks Intelligence Platform and Apache Spark™ to process large-scale distributed datasets About Databricks Databricks is the data and AI company. More than 10,000 organizations worldwide — including Comcast, Condé Nast, Grammarly, and over 50% of the Fortune 500 — rely on the Databricks Data Intelligence Platform to unify and democratize data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe and was founded by the original creators of Lakehouse, Apache Spark™, Delta Lake and MLflow. To learn more, follow Databricks on Twitter , LinkedIn and Facebook . Benefits At Databricks, we strive to provide comprehensi"
Greenhouse,AI Engineer - FDE (Forward Deployed Engineer),databricks,Professional Services Operations,,United States,remote,426,"aws, azure, databricks, gcp, pytorch, rag, spark",,2025-09-10,https://databricks.com/company/careers/open-positions/job?gh_jid=8024010002,"CSQ426R189 The AI Forward Deployed Engineering (AI FDE) team is a highly specialized customer-facing AI team at Databricks. We deliver professional services engagements to help our customers build and productionize first-of-its-kind AI applications. We work cross-functionally to shape long-term strategic priorities and initiatives alongside engineering, product, and developer relations, as well as support internal subject matter expert (SME) teams. We view our team as an ensemble: we look for individuals with strong, unique specializations to improve the overall strength of the team. This team is the right fit for you if you love working with customers, teammates, and fueling your curiosity for the latest trends in GenAI, LLMOps, and ML more broadly. This role can be remote. The impact you will have: Develop cutting-edge GenAI solutions, incorporating the latest techniques from our Mosaic AI Research to solve customer problems Own production rollouts of consumer and internally facing GenAI applications Serve as a trusted technical advisor to customers across a variety of domains Present at conferences such as Data + AI Summit , recognized as a thought leader internally and externally Collaborate cross-functionally with the product and engineering teams to influence priorities and shape the product roadmap What we look for: Experience building GenAI applications, including RAG, multi-agent systems, Text2SQL, fine-tuning, etc., with tools such as HuggingFace, LangChain, and DSPy Expertise in deploying production-grade GenAI applications, including evaluation and optimizations Extensive years of hands-on industry data science experience, leveraging common machine learning and data science tools (i.e., pandas, scikit-learn, PyTorch, etc.) Experience building production-grade machine learning deployments on AWS, Azure, or GCP Graduate degree in a quantitative discipline (Computer Science, Engineering, Statistics, Operations Research, etc.) or equivalent practical experience Experience communicating and/or teaching technical concepts to non-technical and technical audiences alike Passion for collaboration, life-long learning, and driving business value through AI [Preferred] Experience using the Databricks Intelligence Platform and Apache Spark™ to process large-scale distributed datasets Pay Range Transparency Databricks is committed to fair and equitable compensation practices. The pay range(s) for this role is listed below and represents the expected base salary range for non-commissionable roles or on-target earnings for commissionable roles. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to job-related skills, depth of experience, relevant certifications and training, and specific work location. Based on the factors above, Databricks anticipated utilizing the full width of the range. The total compensation package for this position may also include eligibility for annual perfo"
Greenhouse,Data Scientist - New Grad (2026 Start),databricks,University Recruiting,,"Mountain View, California; San Francisco, California",,978,"databricks, python, spark, sql",,2025-09-17,https://databricks.com/company/careers/open-positions/job?gh_jid=6866554002,"(P-978) At Databricks, we are passionate about helping data teams solve the world's toughest problems — from making the next mode of transportation a reality to accelerating the development of medical breakthroughs. We do this by building and running the world's best data and AI infrastructure platform so our customers can use deep data insights to improve their business. As a Data Scientist, you will join the Data team of data scientists and engineers to turn Databricks business and operations data into insights for product design, strategies for customer acquisition/retention, and optimizations to engineering system efficiency/stability/performance. The Data team also functions as an internal ""customer"" that dogfoods the Databricks platform and drives product improvements. We are hiring for the Mountain View, CA office. We will discuss more with you as you move through the process! The Impact You Will Have Work with the Data team and cross-functional stakeholders (Product, Customer Success, Engineering, Sales, Marketing and Finance) to use data to solve problems Apply your expertise in data science methodologies to real data to deliver insights and/or deploy algorithms to the Databricks platform Manage your own project end-to-end from requirements gathering, data exploration to presenting insights to stakeholders and/or deployment an algorithm in a production environment What We Look For You will have graduated in fall 2025 or spring 2026 with a Master's or PhD degree in a quantitative field (e.g., Statistics, Math, Computer Science, Physics, Economics, Operational Research or Engineering) and are looking to start immediately. Proven ability to work with data in SQL and Python Experience with multiple statistical data analysis and machine learning methods such as generalized linear regression, regression and classification trees, unsupervised learning methods, causal inference, stochastic processes, time series forecasting You are excited to solve ambiguous problems with a collaborative team Pay Range Transparency Databricks is committed to fair and equitable compensation practices. The pay range(s) for this role is listed below and represents the expected salary range for non-commissionable roles or on-target earnings for commissionable roles. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to job-related skills, depth of experience, relevant certifications and training, and specific work location. Based on the factors above, Databricks anticipates utilizing the full width of the range. The total compensation package for this position may also include eligibility for annual performance bonus, equity, and the benefits listed above. For more information regarding which range your location is in visit our page here . Local Pay Range $140,000 — $150,000 USD About Databricks Databricks is the data and AI company. More than 10,000 organizations worldwide — including Comcast, Cond"
Greenhouse,Delivery Solutions Architect (Data & AI),databricks,Delivery Solutions Architects,,"Amsterdam, Netherlands",,426,"databricks, python, scala, spark, sql",,2025-09-10,https://databricks.com/company/careers/open-positions/job?gh_jid=8094446002,"REQ ID: CSQ426R252 Recruiter: Dina Hussain Location: Amsterdam, Netherlands (any location in the Netherlands) At Databricks, we are on a mission to empower our customers to solve the world's toughest data problems by utilising the Databricks Data Intelligence Platform. As a Delivery Solutions Architect (DSA), you will play an important role during this journey. You will collaborate with our sales and field engineering teams to accelerate the adoption and growth of the Databricks Platform in your customers. You will also help ensure customer success by increasing focus and technical accountability to our most complex customers who need guidance to accelerate usage on Databricks workloads that they have already selected, helping them maximise the value they get from our platform and the return on investment. This is a hybrid technical and commercial role. It is commercial in the sense that you will drive growth in your assigned customers and use cases through leading your customers' stakeholders, building executive relationships, orchestration other focused/specialised teams within Databricks, and creating and driving plans and strategies for Databricks colleagues to build upon. This is in parallel to being technical, with expectations being that you become the post-sale technical lead across all Databricks products. This requires you to use your skills and technical credibility to engage and communicate at all levels with an organisation. You will report directly to a DSA Manager within the Field Engineering organisation. The impact you will have: Engage with Solutions Architects to understand the full use case demand plan for prioritised customers Lead the post-technical win technical account strategy and execution plan for the majority of Databricks use cases within our most strategic accounts Be the accountable technical leader assigned to specific use cases and customer(s) across multiple selling teams and internal stakeholders, creating certainty from uncertainty and driving onboarding, enablement, success, go-live and healthy consumption of the workloads where the customer has made the decision to consume Databricks Be the first contact for any technical issues or questions related to the production/go live status of agreed-upon use cases within an account, oftentimes serving multiple use cases within the largest and most complex organisations Leverage both Shared Services, User Education, Onboarding/Technical Services and Support resources, along with escalating to expert-level technical experts to build the right tasks that are beyond your scope of activities or expertise Create, own and execute a point of view as to how key use cases can be accelerated into production, coordinating with Professional Services (PS) resources on the delivery of PS Engagement proposals Navigate Databricks Product and Engineering teams for new product Innovations, private previews and upgrade needs Develop an execution plan that covers all activities of all cu"
Greenhouse,"Delivery Solutions Architect (Data & AI, Project Delivery)",databricks,Delivery Solutions Architects,,"London, United Kingdom",,426,"databricks, python, scala, spark, sql",,2025-09-10,https://databricks.com/company/careers/open-positions/job?gh_jid=8128927002,"CSQ426R275 At Databricks, we are on a mission to empower our customers to solve the world's toughest data problems by utilizing the the Databricks Data Intelligence Platform. As a Delivery Solutions Architect (DSA), you will play an important role during this journey. You will collaborate with our sales and field engineering teams to accelerate the adoption and growth of the Databricks platform in your customers. You will also help ensure customer success by increasing focus and technical accountability to our most complex customers who need guidance to accelerate usage on Databricks workloads that they have already selected, helping them maximise the value they get of our platform and the return on investment. This is a hybrid technical and commercial role. It is commercial in the sense that you will drive growth in your assigned customers and use cases through leading your customers' stakeholders, building executive relationships, orchestration of other focused/specialized teams within Databricks, and creating and driving plans and strategies for Databricks colleagues to build upon. This is in parallel to being technical, with expectations being that you become the post-sale technical lead across all Databricks products. This requires you to use your skills and technical credibility to engage and communicate at all levels with an organisation. You will report directly to a DSA Manager within the Field Engineering organization. The impact you will have: Engage with Solutions Architects to understand the full use case demand plan for prioritised customers Lead the post-technical win technical account strategy and execution plan for the majority of Databricks use cases within our most strategic accounts Be the accountable technical leader assigned to specific use cases and customer(s) across multiple selling teams and internal stakeholders, creating certainty from uncertainty and driving onboarding, enablement, success, go-live and healthy consumption of the workloads where the customer has made the decision to consume Databricks Be the first contact for any technical issues or questions related to production/go live status of agreed upon use cases within an account, oftentimes services multiple use cases within the largest and most complex organizations Leverage both Shared Services, User Education, Onboarding/Technical Services and Support resources, along with escalating to expert level technical experts to build the right tasks that are beyond your scope of activities or expertise Create, own and execute a point-of-view as to how key use cases can be accelerated into production, coordinating with Professional Services (PS) resources on the delivery of PS Engagement proposals Navigate Databricks Product and Engineering teams for new product Innovations, private previews and upgrade needs Develop an execution plan that covers all activities of all customer-facing technical roles and teams to cover the below work streams: Main use cases moving fr"
Greenhouse,Engineering Manager - Data + AI Observability,databricks,Executive Engineering - Pipeline,,"Bengaluru, India",,995 ,"databricks, spark",,2025-08-08,https://databricks.com/company/careers/open-positions/job?gh_jid=7884603002,"P-995 Companies are investing billions of dollars into developing and deploying AI and the data platforms that enable it. But do they know what is happening? At Databricks, we are passionate about enabling data teams to solve the world’s toughest problems — from making the next mode of transportation a reality to accelerating the development of medical breakthroughs. We do this by building and running the world’s best data and AI infrastructure platform so our customers can use deep data insights to improve their business. Founded by engineers — and customer obsessed — we leap at every opportunity to tackle technical challenges, from designing next-gen UI/UX for interfacing with data to scaling our services and infrastructure across millions of virtual machines. And we're only getting started. As one of the first Engineering Managers in the Software Engineering team at Databricks India , you will work with your team to develop products that customers use to get insights on their AI and data workloads, optimize their performance, and lower costs and build data infrastructure that processes billions of entries daily, deploy to over 65 cloud regions worldwide, and enable some of the world's biggest companies to conduct their DevOps, FinOps, SecOps and AIOps jobs. The impact you will have: Hire great engineers to build an outstanding team. Ensure high technical standards by instituting processes (architecture reviews, testing) and culture (engineering excellence). Work with engineering and product leadership to build a long-term roadmap. Coordinate execution and collaborate across teams to unblock cross-cutting projects. What we look for: 10+ years of extensive experience with large-scale distributed systems alongside the processes around testing, monitoring, SLAs etc Extensive experience as a Software Engineering Leader , building & scaling software engineering teams from ground up Extensive experience managing a team of strong software engineers Platform mindset: effective building platforms for other software teams , iterating quickly to reduce friction to adoption, advocating for platform use BS (or higher) in Computer Science, or a related field. About Databricks Databricks is the data and AI company. More than 10,000 organizations worldwide — including Comcast, Condé Nast, Grammarly, and over 50% of the Fortune 500 — rely on the Databricks Data Intelligence Platform to unify and democratize data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe and was founded by the original creators of Lakehouse, Apache Spark™, Delta Lake and MLflow. To learn more, follow Databricks on Twitter , LinkedIn and Facebook . Benefits At Databricks, we strive to provide comprehensive benefits and perks that meet the needs of all of our employees. For specific details on the benefits offered in your region, please visit https://www.mybenefitsnow.com/databricks . Our Commitment to Diversity and Inclusion At Databricks, we a"
Greenhouse,"Engineering Manager- AI OSS Ecosystem, Singapore",databricks,Executive Engineering - Pipeline,,Singapore,,1389 ,"databricks, spark",,2025-07-31,https://databricks.com/company/careers/open-positions/job?gh_jid=7917